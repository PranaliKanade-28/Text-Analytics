{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "BBC-FINAL_copy.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9PgZN6X-Xlu"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S73hUwtW-Xlv",
        "outputId": "b2a60107-c589-4087-d719-fc905a2ac691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import TfidfModel\n",
        "from gensim.corpora import Dictionary\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import regexp_tokenize\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk import pos_tag_sents\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA5rWXJs-Xly",
        "outputId": "c93a0d56-a3be-461d-ae43-72ac9888974d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import os\n",
        "import nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "%matplotlib inline\n",
        "stop_words = stopwords.words('english')\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMm7BdcD-Xl1",
        "outputId": "fabc1f82-e982-4635-9627-545701832632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "#reading data from csv file\n",
        "df = pd.read_csv('BBC-articles.csv')\n",
        "df.head(3)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   category                                               text\n",
              "0      tech  tv future in the hands of viewers with home th...\n",
              "1  business  worldcom boss  left books alone  former worldc...\n",
              "2     sport  tigers wary of farrell  gamble  leicester say ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6FQDdmw-Xl8"
      },
      "source": [
        "# words preprocessing \n",
        "data = df.text.values.tolist()\n",
        "\n",
        "# Get words from sentences\n",
        "def getWordsFromSentence(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(getWordsFromSentence(data))\n",
        "\n",
        "\n",
        "# Functions for small words, stopwords and lemmatization\n",
        "def remove_small_words(texts):\n",
        "    return [[w for w in simple_preprocess(str(doc)) if len(w) > 2] for doc in texts]\n",
        "\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def lemmatize(texts):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [[lemmatizer.lemmatize(w) for w in simple_preprocess(str(doc))] for doc in texts]\n",
        "\n",
        "\n",
        "# Do lemmatization\n",
        "tokens = lemmatize(remove_stopwords(data_words))\n",
        "\n",
        "# Remove one letter and two letter words \n",
        "tokens = remove_small_words(tokens)\n",
        "\n",
        "my_dict = Dictionary(tokens)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nVyMpnJ-Xl-"
      },
      "source": [
        "# Count Vectorization\n",
        "dtm = [my_dict.doc2bow(doc) for doc in tokens]\n",
        "    \n",
        "# TF-IDF Vectorization\n",
        "tfidf = TfidfModel(dtm)\n",
        "tfidf = tfidf[dtm]"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKGBQcda-XmC"
      },
      "source": [
        "from gensim.models import LsiModel, LdaModel\n",
        "# LSI with TF-IDF Vector\n",
        "lsi_tfidf = LsiModel(corpus=tfidf, id2word=my_dict, num_topics=5)\n",
        "# LDA with TF-IDF Vector\n",
        "lda_tfidf = LdaModel(corpus=tfidf, id2word=my_dict, num_topics=5)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8OAyrl5-XmF",
        "outputId": "dedcfde5-7f18-4079-e18e-50f91974aefb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "# Get dominant topic and corresponding keywords for each article\n",
        "\n",
        "def getKeywordsFromDominantTopic(model, corpus, texts): \n",
        "    # Init output\n",
        "    topickeyword_df = pd.DataFrame()\n",
        "\n",
        "    # Get main topic in each document\n",
        "    for i, row in enumerate(model[corpus]):\n",
        "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "        # Get the Dominant topic and Keywords for each document\n",
        "        for j, (topic_num, prop_topic) in enumerate(row):\n",
        "            if j == 0:  # => dominant topic\n",
        "                wp = model.show_topic(topic_num)\n",
        "                topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                topickeyword_df = topickeyword_df.append(pd.Series([topic_keywords]), ignore_index=True)\n",
        "            else:\n",
        "                break\n",
        "    return(topickeyword_df)\n",
        "\n",
        "# Assign the keywords for each vectorization and model combination\n",
        "df['LSI TF-IDF Keywords'] = getKeywordsFromDominantTopic(model=lsi_tfidf, corpus=tfidf, texts=df.text)\n",
        "df['LDA TF-IDF Keywords'] = getKeywordsFromDominantTopic(model=lda_tfidf, corpus=tfidf, texts=df.text)\n",
        "df.head(3)\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "      <th>LSI TF-IDF Keywords</th>\n",
              "      <th>LDA TF-IDF Keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "      <td>mobile, phone, film, award, england, best, tec...</td>\n",
              "      <td>blair, bank, election, party, sale, dollar, la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "      <td>film, award, best, oscar, england, actor, game...</td>\n",
              "      <td>blair, bank, election, party, sale, dollar, la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "      <td>film, award, best, oscar, england, actor, game...</td>\n",
              "      <td>mobile, phone, search, game, award, film, play...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   category                                               text  \\\n",
              "0      tech  tv future in the hands of viewers with home th...   \n",
              "1  business  worldcom boss  left books alone  former worldc...   \n",
              "2     sport  tigers wary of farrell  gamble  leicester say ...   \n",
              "\n",
              "                                 LSI TF-IDF Keywords  \\\n",
              "0  mobile, phone, film, award, england, best, tec...   \n",
              "1  film, award, best, oscar, england, actor, game...   \n",
              "2  film, award, best, oscar, england, actor, game...   \n",
              "\n",
              "                                 LDA TF-IDF Keywords  \n",
              "0  blair, bank, election, party, sale, dollar, la...  \n",
              "1  blair, bank, election, party, sale, dollar, la...  \n",
              "2  mobile, phone, search, game, award, film, play...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neN5pkXi-XmH",
        "outputId": "216d7bf2-40a7-4663-e50a-8ddd49bdf453",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "# Get 5 most common keywords across the LSI group of keywords\n",
        "from collections import Counter \n",
        "for i in df.index:\n",
        "    words = df.loc[i, 'LSI TF-IDF Keywords']\n",
        "    words = words.split(',')\n",
        "    most_occur = Counter(words).most_common(5) \n",
        "    df.loc[i, 'Top 5 Freq Words(LSI(I))'] = ','.join([word[0] for word in most_occur])\n",
        "\n",
        "for i in df.index:\n",
        "    words = df.loc[i, 'LDA TF-IDF Keywords']\n",
        "    words = words.split(',')\n",
        "    most_occur = Counter(words).most_common(5) \n",
        "    df.loc[i, 'Top 5 Freq Words(LDA(I))'] = ','.join([word[0] for word in most_occur]) \n",
        "    \n",
        "df = df.drop(columns=['LSI TF-IDF Keywords','LDA TF-IDF Keywords'])\n",
        "df[['text', 'Top 5 Freq Words(LSI(I))', 'Top 5 Freq Words(LDA(I))']].head(3)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Top 5 Freq Words(LSI(I))</th>\n",
              "      <th>Top 5 Freq Words(LDA(I))</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "      <td>mobile, phone, film, award, england</td>\n",
              "      <td>blair, bank, election, party, sale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "      <td>film, award, best, oscar, england</td>\n",
              "      <td>blair, bank, election, party, sale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "      <td>film, award, best, oscar, england</td>\n",
              "      <td>mobile, phone, search, game, award</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0  tv future in the hands of viewers with home th...   \n",
              "1  worldcom boss  left books alone  former worldc...   \n",
              "2  tigers wary of farrell  gamble  leicester say ...   \n",
              "\n",
              "              Top 5 Freq Words(LSI(I))            Top 5 Freq Words(LDA(I))  \n",
              "0  mobile, phone, film, award, england  blair, bank, election, party, sale  \n",
              "1    film, award, best, oscar, england  blair, bank, election, party, sale  \n",
              "2    film, award, best, oscar, england  mobile, phone, search, game, award  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNJqN1dl-XmK"
      },
      "source": [
        "#### 2 ) With term frequency filter, to exclude the top 10% of the most frequent words and words that appear less than 5 times in the documents (drawing from Zipf's Law)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvq5A6mr-XmK",
        "outputId": "78879f1f-016c-417b-c948-7f45d6b2c983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "my_dict.filter_extremes(no_below=5, no_above=0.90)\n",
        "len(my_dict.token2id)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7896"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAU8-A_C-XmM"
      },
      "source": [
        "# Count Vectorization\n",
        "dtm = [my_dict.doc2bow(doc) for doc in tokens]\n",
        "    \n",
        "# TF-IDF Vectorization\n",
        "tfidf = TfidfModel(dtm)\n",
        "tfidf = tfidf[dtm]"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtLTrssd-XmQ"
      },
      "source": [
        "from gensim.models import LsiModel, LdaModel\n",
        "# LSI with TF-IDF Vector\n",
        "lsi_tfidf = LsiModel(corpus=tfidf, id2word=my_dict, num_topics=5)\n",
        "# LDA with TF-IDF Vector\n",
        "lda_tfidf = LdaModel(corpus=tfidf, id2word=my_dict, num_topics=5)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulUaSz7D-XmS",
        "outputId": "b9b5dc26-f3f6-4296-fe27-3d02ae7b0996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df['LSI TF-IDF Keywords'] = getKeywordsFromDominantTopic(model=lsi_tfidf, corpus=tfidf, texts=df.text)\n",
        "df['LDA TF-IDF Keywords'] = getKeywordsFromDominantTopic(model=lda_tfidf, corpus=tfidf, texts=df.text)\n",
        "\n",
        "df.head(3)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "      <th>Top 5 Freq Words(LSI(I))</th>\n",
              "      <th>Top 5 Freq Words(LDA(I))</th>\n",
              "      <th>LSI TF-IDF Keywords</th>\n",
              "      <th>LDA TF-IDF Keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "      <td>mobile, phone, film, award, england</td>\n",
              "      <td>blair, bank, election, party, sale</td>\n",
              "      <td>mobile, phone, economy, growth, rate, bank, fi...</td>\n",
              "      <td>mobile, phone, search, sale, blair, election, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "      <td>film, award, best, oscar, england</td>\n",
              "      <td>blair, bank, election, party, sale</td>\n",
              "      <td>labour, election, blair, brown, tory, party, t...</td>\n",
              "      <td>mobile, phone, search, sale, blair, election, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "      <td>film, award, best, oscar, england</td>\n",
              "      <td>mobile, phone, search, game, award</td>\n",
              "      <td>mobile, phone, film, award, best, technology, ...</td>\n",
              "      <td>film, award, holmes, game, nomination, england...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   category                                               text  \\\n",
              "0      tech  tv future in the hands of viewers with home th...   \n",
              "1  business  worldcom boss  left books alone  former worldc...   \n",
              "2     sport  tigers wary of farrell  gamble  leicester say ...   \n",
              "\n",
              "              Top 5 Freq Words(LSI(I))            Top 5 Freq Words(LDA(I))  \\\n",
              "0  mobile, phone, film, award, england  blair, bank, election, party, sale   \n",
              "1    film, award, best, oscar, england  blair, bank, election, party, sale   \n",
              "2    film, award, best, oscar, england  mobile, phone, search, game, award   \n",
              "\n",
              "                                 LSI TF-IDF Keywords  \\\n",
              "0  mobile, phone, economy, growth, rate, bank, fi...   \n",
              "1  labour, election, blair, brown, tory, party, t...   \n",
              "2  mobile, phone, film, award, best, technology, ...   \n",
              "\n",
              "                                 LDA TF-IDF Keywords  \n",
              "0  mobile, phone, search, sale, blair, election, ...  \n",
              "1  mobile, phone, search, sale, blair, election, ...  \n",
              "2  film, award, holmes, game, nomination, england...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "v1qy2zxR-XmV",
        "outputId": "1a88ec5e-6ba5-4502-927c-3b5a5f40bf07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "# Get 5 most common keywords across the LSI group of keywords\n",
        "from collections import Counter \n",
        "for i in df.index:\n",
        "    words = df.loc[i, 'LSI TF-IDF Keywords']\n",
        "    words = words.split(',')\n",
        "    most_occur = Counter(words).most_common(5) \n",
        "    df.loc[i, 'Top 5 Freq Words(LSI(II))'] = ','.join([word[0] for word in most_occur])\n",
        "\n",
        "for i in df.index:\n",
        "    words = df.loc[i, 'LDA TF-IDF Keywords']\n",
        "    words = words.split(',')\n",
        "    most_occur = Counter(words).most_common(5) \n",
        "    df.loc[i, 'Top 5 Freq Words(LDA(II))'] = ','.join([word[0] for word in most_occur]) \n",
        "    \n",
        "df = df.drop(columns=['LSI TF-IDF Keywords','LDA TF-IDF Keywords'])\n",
        "pd.set_option('display.max_columns', None)\n",
        "df[['text', 'Top 5 Freq Words(LSI(II))', 'Top 5 Freq Words(LDA(II))']].head(3)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Top 5 Freq Words(LSI(II))</th>\n",
              "      <th>Top 5 Freq Words(LDA(II))</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "      <td>mobile, phone, economy, growth, rate</td>\n",
              "      <td>mobile, phone, search, sale, blair</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "      <td>labour, election, blair, brown, tory</td>\n",
              "      <td>mobile, phone, search, sale, blair</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "      <td>mobile, phone, film, award, best</td>\n",
              "      <td>film, award, holmes, game, nomination</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0  tv future in the hands of viewers with home th...   \n",
              "1  worldcom boss  left books alone  former worldc...   \n",
              "2  tigers wary of farrell  gamble  leicester say ...   \n",
              "\n",
              "              Top 5 Freq Words(LSI(II))              Top 5 Freq Words(LDA(II))  \n",
              "0  mobile, phone, economy, growth, rate     mobile, phone, search, sale, blair  \n",
              "1  labour, election, blair, brown, tory     mobile, phone, search, sale, blair  \n",
              "2      mobile, phone, film, award, best  film, award, holmes, game, nomination  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBnAkC3i-XmX"
      },
      "source": [
        "## 3) With a part of speech filter, to limit your TD-IDF matrix to nouns only. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiC8hU36U9fZ",
        "outputId": "6d49d936-c3b1-4121-bf8d-1701e28f5219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnqOVECL-Xmb"
      },
      "source": [
        "# Matrix of nouns\n",
        "text = ''.join(str(e) for e in tokens)\n",
        "text_pos=word_tokenize(text)\n",
        "pos_tag=nltk.pos_tag(text_pos)\n",
        "nouns=list(filter(lambda x: x[1] == 'NN', pos_tag))\n",
        "nounlist = list(nouns)\n",
        "\n",
        "def remove_small_words(texts):\n",
        "    return [[w for w in simple_preprocess(str(doc)) if len(w) > 2] for doc in texts]\n",
        "\n",
        "tokens = remove_small_words(nounlist)\n",
        "my_dict = Dictionary(tokens)\n",
        "\n",
        "# Count Vectorization\n",
        "dtm = [my_dict.doc2bow(doc) for doc in tokens]"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZOU0Jyl-Xmr"
      },
      "source": [
        "# TF-IDF Vectorization\n",
        "tfidf = TfidfModel(dtm)\n",
        "tfidf = tfidf[dtm]"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoNLOjBz-Xmu"
      },
      "source": [
        "from gensim.models import LsiModel, LdaModel\n",
        "# LSI with TF-IDF Vector\n",
        "lsi_tfidf = LsiModel(corpus=tfidf, id2word=my_dict, num_topics=5)\n",
        "# LDA with TF-IDF Vector\n",
        "lda_tfidf = LdaModel(corpus=tfidf, id2word=my_dict, num_topics=5)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mXnzSep-Xmw",
        "outputId": "536b6110-f267-4864-8508-fb065f73de2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "# Get dominant topic and corresponding keywords for each article\n",
        "\n",
        "def getKeywordsFromDominantTopic(model, corpus, texts): \n",
        "    # Init output\n",
        "    topickeyword_df = pd.DataFrame()\n",
        "\n",
        "    # Get main topic in each document\n",
        "    for i, row in enumerate(model[corpus]):\n",
        "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "        # Get the Dominant topic and Keywords for each document\n",
        "        for j, (topic_num, prop_topic) in enumerate(row):\n",
        "            if j == 0:  # => dominant topic\n",
        "                wp = model.show_topic(topic_num)\n",
        "                topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                topickeyword_df = topickeyword_df.append(pd.Series([topic_keywords]), ignore_index=True)\n",
        "            else:\n",
        "                break\n",
        "    return(topickeyword_df)\n",
        "\n",
        "# Assign the keywords for each vectorization and model combination\n",
        "df['LSI TF-IDF Keywords'] = getKeywordsFromDominantTopic(model=lsi_tfidf, corpus=tfidf, texts=df.text)\n",
        "df['LDA TF-IDF Keywords'] = getKeywordsFromDominantTopic(model=lda_tfidf, corpus=tfidf, texts=df.text)\n",
        "df.head(3)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "      <th>Top 5 Freq Words(LSI(I))</th>\n",
              "      <th>Top 5 Freq Words(LDA(I))</th>\n",
              "      <th>Top 5 Freq Words(LSI(II))</th>\n",
              "      <th>Top 5 Freq Words(LDA(II))</th>\n",
              "      <th>LSI TF-IDF Keywords</th>\n",
              "      <th>LDA TF-IDF Keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "      <td>mobile, phone, film, award, england</td>\n",
              "      <td>blair, bank, election, party, sale</td>\n",
              "      <td>mobile, phone, economy, growth, rate</td>\n",
              "      <td>mobile, phone, search, sale, blair</td>\n",
              "      <td>future, option, opinion, innovation, investiga...</td>\n",
              "      <td>future, picture, try, version, chance, commiss...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "      <td>film, award, best, oscar, england</td>\n",
              "      <td>blair, bank, election, party, sale</td>\n",
              "      <td>labour, election, blair, brown, tory</td>\n",
              "      <td>mobile, phone, search, sale, blair</td>\n",
              "      <td>country, option, construction, ambition, admin...</td>\n",
              "      <td>country, image, decision, medium, pressure, de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "      <td>film, award, best, oscar, england</td>\n",
              "      <td>mobile, phone, search, game, award</td>\n",
              "      <td>mobile, phone, film, award, best</td>\n",
              "      <td>film, award, holmes, game, nomination</td>\n",
              "      <td>country, option, construction, ambition, admin...</td>\n",
              "      <td>country, image, decision, medium, pressure, de...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   category                                               text  \\\n",
              "0      tech  tv future in the hands of viewers with home th...   \n",
              "1  business  worldcom boss  left books alone  former worldc...   \n",
              "2     sport  tigers wary of farrell  gamble  leicester say ...   \n",
              "\n",
              "              Top 5 Freq Words(LSI(I))            Top 5 Freq Words(LDA(I))  \\\n",
              "0  mobile, phone, film, award, england  blair, bank, election, party, sale   \n",
              "1    film, award, best, oscar, england  blair, bank, election, party, sale   \n",
              "2    film, award, best, oscar, england  mobile, phone, search, game, award   \n",
              "\n",
              "              Top 5 Freq Words(LSI(II))  \\\n",
              "0  mobile, phone, economy, growth, rate   \n",
              "1  labour, election, blair, brown, tory   \n",
              "2      mobile, phone, film, award, best   \n",
              "\n",
              "               Top 5 Freq Words(LDA(II))  \\\n",
              "0     mobile, phone, search, sale, blair   \n",
              "1     mobile, phone, search, sale, blair   \n",
              "2  film, award, holmes, game, nomination   \n",
              "\n",
              "                                 LSI TF-IDF Keywords  \\\n",
              "0  future, option, opinion, innovation, investiga...   \n",
              "1  country, option, construction, ambition, admin...   \n",
              "2  country, option, construction, ambition, admin...   \n",
              "\n",
              "                                 LDA TF-IDF Keywords  \n",
              "0  future, picture, try, version, chance, commiss...  \n",
              "1  country, image, decision, medium, pressure, de...  \n",
              "2  country, image, decision, medium, pressure, de...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dsasrgN-Xmz",
        "outputId": "75c6def8-74ca-42cd-d0eb-0ff0d51f1821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "# Get 5 most common keywords across the LSI group of keywords\n",
        "from collections import Counter \n",
        "for i in df.index:\n",
        "    words = df.loc[i, 'LSI TF-IDF Keywords']\n",
        "    words = words.split(',')\n",
        "    most_occur = Counter(words).most_common(5) \n",
        "    df.loc[i, 'Top 5 Freq Words(LSI(III))'] = ','.join([word[0] for word in most_occur])\n",
        "\n",
        "for i in df.index:\n",
        "    words = df.loc[i, 'LDA TF-IDF Keywords']\n",
        "    words = words.split(',')\n",
        "    most_occur = Counter(words).most_common(5) \n",
        "    df.loc[i, 'Top 5 Freq Words(LDA(III))'] = ','.join([word[0] for word in most_occur]) \n",
        "    \n",
        "df[['text', 'Top 5 Freq Words(LSI(III))', 'Top 5 Freq Words(LDA(III))']].head(3)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Top 5 Freq Words(LSI(III))</th>\n",
              "      <th>Top 5 Freq Words(LDA(III))</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "      <td>future, option, opinion, innovation, investiga...</td>\n",
              "      <td>future, picture, try, version, chance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "      <td>country, option, construction, ambition, admin...</td>\n",
              "      <td>country, image, decision, medium, pressure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "      <td>country, option, construction, ambition, admin...</td>\n",
              "      <td>country, image, decision, medium, pressure</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0  tv future in the hands of viewers with home th...   \n",
              "1  worldcom boss  left books alone  former worldc...   \n",
              "2  tigers wary of farrell  gamble  leicester say ...   \n",
              "\n",
              "                          Top 5 Freq Words(LSI(III))  \\\n",
              "0  future, option, opinion, innovation, investiga...   \n",
              "1  country, option, construction, ambition, admin...   \n",
              "2  country, option, construction, ambition, admin...   \n",
              "\n",
              "                   Top 5 Freq Words(LDA(III))  \n",
              "0       future, picture, try, version, chance  \n",
              "1  country, image, decision, medium, pressure  \n",
              "2  country, image, decision, medium, pressure  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1IIiA_4-Xm0",
        "outputId": "a50cd714-5ba7-402e-b75d-55fab11e89e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "df = df.drop(columns=['LSI TF-IDF Keywords','LDA TF-IDF Keywords'])\n",
        "df.head()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "      <th>Top 5 Freq Words(LSI(I))</th>\n",
              "      <th>Top 5 Freq Words(LDA(I))</th>\n",
              "      <th>Top 5 Freq Words(LSI(II))</th>\n",
              "      <th>Top 5 Freq Words(LDA(II))</th>\n",
              "      <th>Top 5 Freq Words(LSI(III))</th>\n",
              "      <th>Top 5 Freq Words(LDA(III))</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "      <td>mobile, phone, film, award, england</td>\n",
              "      <td>blair, bank, election, party, sale</td>\n",
              "      <td>mobile, phone, economy, growth, rate</td>\n",
              "      <td>mobile, phone, search, sale, blair</td>\n",
              "      <td>future, option, opinion, innovation, investiga...</td>\n",
              "      <td>future, picture, try, version, chance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "      <td>film, award, best, oscar, england</td>\n",
              "      <td>blair, bank, election, party, sale</td>\n",
              "      <td>labour, election, blair, brown, tory</td>\n",
              "      <td>mobile, phone, search, sale, blair</td>\n",
              "      <td>country, option, construction, ambition, admin...</td>\n",
              "      <td>country, image, decision, medium, pressure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "      <td>film, award, best, oscar, england</td>\n",
              "      <td>mobile, phone, search, game, award</td>\n",
              "      <td>mobile, phone, film, award, best</td>\n",
              "      <td>film, award, holmes, game, nomination</td>\n",
              "      <td>country, option, construction, ambition, admin...</td>\n",
              "      <td>country, image, decision, medium, pressure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "      <td>film, award, best, oscar, england</td>\n",
              "      <td>blair, bank, election, party, sale</td>\n",
              "      <td>mobile, phone, film, award, best</td>\n",
              "      <td>ferguson, united, arsenal, blunkett, campbell</td>\n",
              "      <td>country, option, construction, ambition, admin...</td>\n",
              "      <td>country, image, decision, medium, pressure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
              "      <td>mobile, economy, growth, rate, phone</td>\n",
              "      <td>blair, bank, election, party, sale</td>\n",
              "      <td>film, award, oscar, england, best</td>\n",
              "      <td>film, award, holmes, game, nomination</td>\n",
              "      <td>figure, region, venture, alliance, function</td>\n",
              "      <td>future, picture, try, version, chance</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        category                                               text  \\\n",
              "0           tech  tv future in the hands of viewers with home th...   \n",
              "1       business  worldcom boss  left books alone  former worldc...   \n",
              "2          sport  tigers wary of farrell  gamble  leicester say ...   \n",
              "3          sport  yeading face newcastle in fa cup premiership s...   \n",
              "4  entertainment  ocean s twelve raids box office ocean s twelve...   \n",
              "\n",
              "               Top 5 Freq Words(LSI(I))            Top 5 Freq Words(LDA(I))  \\\n",
              "0   mobile, phone, film, award, england  blair, bank, election, party, sale   \n",
              "1     film, award, best, oscar, england  blair, bank, election, party, sale   \n",
              "2     film, award, best, oscar, england  mobile, phone, search, game, award   \n",
              "3     film, award, best, oscar, england  blair, bank, election, party, sale   \n",
              "4  mobile, economy, growth, rate, phone  blair, bank, election, party, sale   \n",
              "\n",
              "              Top 5 Freq Words(LSI(II))  \\\n",
              "0  mobile, phone, economy, growth, rate   \n",
              "1  labour, election, blair, brown, tory   \n",
              "2      mobile, phone, film, award, best   \n",
              "3      mobile, phone, film, award, best   \n",
              "4     film, award, oscar, england, best   \n",
              "\n",
              "                       Top 5 Freq Words(LDA(II))  \\\n",
              "0             mobile, phone, search, sale, blair   \n",
              "1             mobile, phone, search, sale, blair   \n",
              "2          film, award, holmes, game, nomination   \n",
              "3  ferguson, united, arsenal, blunkett, campbell   \n",
              "4          film, award, holmes, game, nomination   \n",
              "\n",
              "                          Top 5 Freq Words(LSI(III))  \\\n",
              "0  future, option, opinion, innovation, investiga...   \n",
              "1  country, option, construction, ambition, admin...   \n",
              "2  country, option, construction, ambition, admin...   \n",
              "3  country, option, construction, ambition, admin...   \n",
              "4        figure, region, venture, alliance, function   \n",
              "\n",
              "                   Top 5 Freq Words(LDA(III))  \n",
              "0       future, picture, try, version, chance  \n",
              "1  country, image, decision, medium, pressure  \n",
              "2  country, image, decision, medium, pressure  \n",
              "3  country, image, decision, medium, pressure  \n",
              "4       future, picture, try, version, chance  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtK1MK77ohyp",
        "outputId": "ecae5272-d71c-4627-b014-26fb8912c9fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "# Combine all the keywords\n",
        "df['merged-keywords'] = df['Top 5 Freq Words(LDA(I))'] + ', ' + df['Top 5 Freq Words(LDA(II))'] + ', ' + df['Top 5 Freq Words(LDA(III))'] + ', ' + df['Top 5 Freq Words(LSI(I))'] + ', ' + df['Top 5 Freq Words(LSI(II))']+ ', ' + df['Top 5 Freq Words(LSI(III))']\n",
        "\n",
        "# Get 5 most common keywords across all the groups of keywords\n",
        "from collections import Counter \n",
        "for i in df.index:\n",
        "    words = df.loc[i, 'merged-keywords']\n",
        "    words = words.split(',')\n",
        "    most_occur = Counter(words).most_common(5) \n",
        "    df.loc[i, 'Top 5 Freq Words'] = ','.join([word[0] for word in most_occur])\n",
        "\n",
        "df[['text', 'Top 5 Freq Words']].head(3)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Top 5 Freq Words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "      <td>mobile, phone, sale, future,blair</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "      <td>election, sale, blair, country,blair</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "      <td>award, film, phone, game, country</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0  tv future in the hands of viewers with home th...   \n",
              "1  worldcom boss  left books alone  former worldc...   \n",
              "2  tigers wary of farrell  gamble  leicester say ...   \n",
              "\n",
              "                        Top 5 Freq Words  \n",
              "0      mobile, phone, sale, future,blair  \n",
              "1   election, sale, blair, country,blair  \n",
              "2      award, film, phone, game, country  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWv5WCo-YvhP"
      },
      "source": [
        "# Finding best method of all for given article\n",
        "\n",
        "for i in range(len(df)):\n",
        "    method=''\n",
        "    y=0\n",
        "    y=len(set(df['Top 5 Freq Words'][i])-set(df['Top 5 Freq Words(LSI(I))'][i]))\n",
        "    method='LSI(I) Algorithm'\n",
        "    if y>len(set(df['Top 5 Freq Words(LDA(I))'][i])-set(df['Top 5 Freq Words'][i])):\n",
        "        method='LDA(I) Algorithm'\n",
        "        y=len(set(df['Top 5 Freq Words(LDA(I))'][i])-set(df['Top 5 Freq Words'][i]))\n",
        "    elif y>len(set(df['Top 5 Freq Words(LSI(II))'][i])-set(df['Top 5 Freq Words'][i])):\n",
        "        method='LSI(II) Algorithm'\n",
        "        y=len(set(df['Top 5 Freq Words(LSI(II))'][i])-set(df['Top 5 Freq Words'][i]))\n",
        "    elif y>len(set(df['Top 5 Freq Words(LDA(II))'][i])-set(df['Top 5 Freq Words'][i])):\n",
        "        method='LDA(II) Algorithm'\n",
        "        y=len(set(df['Top 5 Freq Words(LDA(II))'][i])-set(df['Top 5 Freq Words'][i]))\n",
        "    elif y>len(set(df['Top 5 Freq Words(LSI(III))'][i])-set(df['Top 5 Freq Words'][i])):\n",
        "        method='LSI(III) Algorithm'\n",
        "        y=len(set(df['Top 5 Freq Words(LSI(III))'][i])-set(df['Top 5 Freq Words'][i]))\n",
        "    elif y>len(set(df['Top 5 Freq Words(LDA(III))'][i])-set(df['Top 5 Freq Words'][i])):\n",
        "        method='LDA(III) Algorithm'\n",
        "    df.at[i,'Best_Method']='Best model for this article is '+method\n"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYaKhNM7-Xm2",
        "outputId": "9413041e-5ea2-4a97-c5c9-457f8eb7bde3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "source": [
        "df = df.drop(columns=['merged-keywords','Top 5 Freq Words'])\n",
        "df.head()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "      <th>Top 5 Freq Words(LSI(I))</th>\n",
              "      <th>Top 5 Freq Words(LDA(I))</th>\n",
              "      <th>Top 5 Freq Words(LSI(II))</th>\n",
              "      <th>Top 5 Freq Words(LDA(II))</th>\n",
              "      <th>Top 5 Freq Words(LSI(III))</th>\n",
              "      <th>Top 5 Freq Words(LDA(III))</th>\n",
              "      <th>Best_Method</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "      <td>mobile, phone, film, award, england</td>\n",
              "      <td>blair, bank, election, party, sale</td>\n",
              "      <td>mobile, phone, economy, growth, rate</td>\n",
              "      <td>mobile, phone, search, sale, blair</td>\n",
              "      <td>future, option, opinion, innovation, investiga...</td>\n",
              "      <td>future, picture, try, version, chance</td>\n",
              "      <td>Best model for this article is LDA(II) Algorithm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "      <td>film, award, best, oscar, england</td>\n",
              "      <td>blair, bank, election, party, sale</td>\n",
              "      <td>labour, election, blair, brown, tory</td>\n",
              "      <td>mobile, phone, search, sale, blair</td>\n",
              "      <td>country, option, construction, ambition, admin...</td>\n",
              "      <td>country, image, decision, medium, pressure</td>\n",
              "      <td>Best model for this article is LSI(II) Algorithm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "      <td>film, award, best, oscar, england</td>\n",
              "      <td>mobile, phone, search, game, award</td>\n",
              "      <td>mobile, phone, film, award, best</td>\n",
              "      <td>film, award, holmes, game, nomination</td>\n",
              "      <td>country, option, construction, ambition, admin...</td>\n",
              "      <td>country, image, decision, medium, pressure</td>\n",
              "      <td>Best model for this article is LDA(I) Algorithm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "      <td>film, award, best, oscar, england</td>\n",
              "      <td>blair, bank, election, party, sale</td>\n",
              "      <td>mobile, phone, film, award, best</td>\n",
              "      <td>ferguson, united, arsenal, blunkett, campbell</td>\n",
              "      <td>country, option, construction, ambition, admin...</td>\n",
              "      <td>country, image, decision, medium, pressure</td>\n",
              "      <td>Best model for this article is LSI(III) Algorithm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
              "      <td>mobile, economy, growth, rate, phone</td>\n",
              "      <td>blair, bank, election, party, sale</td>\n",
              "      <td>film, award, oscar, england, best</td>\n",
              "      <td>film, award, holmes, game, nomination</td>\n",
              "      <td>figure, region, venture, alliance, function</td>\n",
              "      <td>future, picture, try, version, chance</td>\n",
              "      <td>Best model for this article is LSI(II) Algorithm</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        category                                               text  \\\n",
              "0           tech  tv future in the hands of viewers with home th...   \n",
              "1       business  worldcom boss  left books alone  former worldc...   \n",
              "2          sport  tigers wary of farrell  gamble  leicester say ...   \n",
              "3          sport  yeading face newcastle in fa cup premiership s...   \n",
              "4  entertainment  ocean s twelve raids box office ocean s twelve...   \n",
              "\n",
              "               Top 5 Freq Words(LSI(I))            Top 5 Freq Words(LDA(I))  \\\n",
              "0   mobile, phone, film, award, england  blair, bank, election, party, sale   \n",
              "1     film, award, best, oscar, england  blair, bank, election, party, sale   \n",
              "2     film, award, best, oscar, england  mobile, phone, search, game, award   \n",
              "3     film, award, best, oscar, england  blair, bank, election, party, sale   \n",
              "4  mobile, economy, growth, rate, phone  blair, bank, election, party, sale   \n",
              "\n",
              "              Top 5 Freq Words(LSI(II))  \\\n",
              "0  mobile, phone, economy, growth, rate   \n",
              "1  labour, election, blair, brown, tory   \n",
              "2      mobile, phone, film, award, best   \n",
              "3      mobile, phone, film, award, best   \n",
              "4     film, award, oscar, england, best   \n",
              "\n",
              "                       Top 5 Freq Words(LDA(II))  \\\n",
              "0             mobile, phone, search, sale, blair   \n",
              "1             mobile, phone, search, sale, blair   \n",
              "2          film, award, holmes, game, nomination   \n",
              "3  ferguson, united, arsenal, blunkett, campbell   \n",
              "4          film, award, holmes, game, nomination   \n",
              "\n",
              "                          Top 5 Freq Words(LSI(III))  \\\n",
              "0  future, option, opinion, innovation, investiga...   \n",
              "1  country, option, construction, ambition, admin...   \n",
              "2  country, option, construction, ambition, admin...   \n",
              "3  country, option, construction, ambition, admin...   \n",
              "4        figure, region, venture, alliance, function   \n",
              "\n",
              "                   Top 5 Freq Words(LDA(III))  \\\n",
              "0       future, picture, try, version, chance   \n",
              "1  country, image, decision, medium, pressure   \n",
              "2  country, image, decision, medium, pressure   \n",
              "3  country, image, decision, medium, pressure   \n",
              "4       future, picture, try, version, chance   \n",
              "\n",
              "                                         Best_Method  \n",
              "0   Best model for this article is LDA(II) Algorithm  \n",
              "1   Best model for this article is LSI(II) Algorithm  \n",
              "2    Best model for this article is LDA(I) Algorithm  \n",
              "3  Best model for this article is LSI(III) Algorithm  \n",
              "4   Best model for this article is LSI(II) Algorithm  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTpUkCSLmNUC"
      },
      "source": [
        "# Exporting the dataframe as a csv file\n",
        "df.to_csv('BBC News Keywords.csv',index=False,encoding='utf-8')"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXhU67OtmyGK",
        "outputId": "544aeec5-bf1f-4dc6-c00f-16cf982c4cbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "df.groupby('Best_Method').count()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "      <th>Top 5 Freq Words(LSI(I))</th>\n",
              "      <th>Top 5 Freq Words(LDA(I))</th>\n",
              "      <th>Top 5 Freq Words(LSI(II))</th>\n",
              "      <th>Top 5 Freq Words(LDA(II))</th>\n",
              "      <th>Top 5 Freq Words(LSI(III))</th>\n",
              "      <th>Top 5 Freq Words(LDA(III))</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Best_Method</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Best model for this article is LDA(I) Algorithm</th>\n",
              "      <td>1315</td>\n",
              "      <td>1315</td>\n",
              "      <td>1315</td>\n",
              "      <td>1315</td>\n",
              "      <td>1315</td>\n",
              "      <td>1315</td>\n",
              "      <td>1315</td>\n",
              "      <td>1315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Best model for this article is LDA(II) Algorithm</th>\n",
              "      <td>264</td>\n",
              "      <td>264</td>\n",
              "      <td>264</td>\n",
              "      <td>264</td>\n",
              "      <td>264</td>\n",
              "      <td>264</td>\n",
              "      <td>264</td>\n",
              "      <td>264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Best model for this article is LDA(III) Algorithm</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Best model for this article is LSI(I) Algorithm</th>\n",
              "      <td>464</td>\n",
              "      <td>464</td>\n",
              "      <td>464</td>\n",
              "      <td>464</td>\n",
              "      <td>464</td>\n",
              "      <td>464</td>\n",
              "      <td>464</td>\n",
              "      <td>464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Best model for this article is LSI(II) Algorithm</th>\n",
              "      <td>173</td>\n",
              "      <td>173</td>\n",
              "      <td>173</td>\n",
              "      <td>173</td>\n",
              "      <td>173</td>\n",
              "      <td>173</td>\n",
              "      <td>173</td>\n",
              "      <td>173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Best model for this article is LSI(III) Algorithm</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   category  text  \\\n",
              "Best_Method                                                         \n",
              "Best model for this article is LDA(I) Algorithm        1315  1315   \n",
              "Best model for this article is LDA(II) Algorithm        264   264   \n",
              "Best model for this article is LDA(III) Algorithm         4     4   \n",
              "Best model for this article is LSI(I) Algorithm         464   464   \n",
              "Best model for this article is LSI(II) Algorithm        173   173   \n",
              "Best model for this article is LSI(III) Algorithm         5     5   \n",
              "\n",
              "                                                   Top 5 Freq Words(LSI(I))  \\\n",
              "Best_Method                                                                   \n",
              "Best model for this article is LDA(I) Algorithm                        1315   \n",
              "Best model for this article is LDA(II) Algorithm                        264   \n",
              "Best model for this article is LDA(III) Algorithm                         4   \n",
              "Best model for this article is LSI(I) Algorithm                         464   \n",
              "Best model for this article is LSI(II) Algorithm                        173   \n",
              "Best model for this article is LSI(III) Algorithm                         5   \n",
              "\n",
              "                                                   Top 5 Freq Words(LDA(I))  \\\n",
              "Best_Method                                                                   \n",
              "Best model for this article is LDA(I) Algorithm                        1315   \n",
              "Best model for this article is LDA(II) Algorithm                        264   \n",
              "Best model for this article is LDA(III) Algorithm                         4   \n",
              "Best model for this article is LSI(I) Algorithm                         464   \n",
              "Best model for this article is LSI(II) Algorithm                        173   \n",
              "Best model for this article is LSI(III) Algorithm                         5   \n",
              "\n",
              "                                                   Top 5 Freq Words(LSI(II))  \\\n",
              "Best_Method                                                                    \n",
              "Best model for this article is LDA(I) Algorithm                         1315   \n",
              "Best model for this article is LDA(II) Algorithm                         264   \n",
              "Best model for this article is LDA(III) Algorithm                          4   \n",
              "Best model for this article is LSI(I) Algorithm                          464   \n",
              "Best model for this article is LSI(II) Algorithm                         173   \n",
              "Best model for this article is LSI(III) Algorithm                          5   \n",
              "\n",
              "                                                   Top 5 Freq Words(LDA(II))  \\\n",
              "Best_Method                                                                    \n",
              "Best model for this article is LDA(I) Algorithm                         1315   \n",
              "Best model for this article is LDA(II) Algorithm                         264   \n",
              "Best model for this article is LDA(III) Algorithm                          4   \n",
              "Best model for this article is LSI(I) Algorithm                          464   \n",
              "Best model for this article is LSI(II) Algorithm                         173   \n",
              "Best model for this article is LSI(III) Algorithm                          5   \n",
              "\n",
              "                                                   Top 5 Freq Words(LSI(III))  \\\n",
              "Best_Method                                                                     \n",
              "Best model for this article is LDA(I) Algorithm                          1315   \n",
              "Best model for this article is LDA(II) Algorithm                          264   \n",
              "Best model for this article is LDA(III) Algorithm                           4   \n",
              "Best model for this article is LSI(I) Algorithm                           464   \n",
              "Best model for this article is LSI(II) Algorithm                          173   \n",
              "Best model for this article is LSI(III) Algorithm                           5   \n",
              "\n",
              "                                                   Top 5 Freq Words(LDA(III))  \n",
              "Best_Method                                                                    \n",
              "Best model for this article is LDA(I) Algorithm                          1315  \n",
              "Best model for this article is LDA(II) Algorithm                          264  \n",
              "Best model for this article is LDA(III) Algorithm                           4  \n",
              "Best model for this article is LSI(I) Algorithm                           464  \n",
              "Best model for this article is LSI(II) Algorithm                          173  \n",
              "Best model for this article is LSI(III) Algorithm                           5  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weFFEQeZpspl"
      },
      "source": [
        "\n",
        "Six different combination of vectorization(Count and TF-IDF), LSI and LDA, most frequent words, and speech filter of noun. From the result we can observer that LDA(I) algorithm works best as count is maximum for same. LDA algorithm with TF-IDF vectorization is best on the dataset as the keywords from the most dominant topic are more relevant and descriptive for each article.\n",
        "\n",
        "After LDA(I) second best LSI(I) algorithm followed by LDA(II) and LSI(II). LSI(III) and LDA(III) performed poorest.\n",
        "\n"
      ]
    }
  ]
}